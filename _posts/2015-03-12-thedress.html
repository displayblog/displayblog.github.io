---
layout: post
status: publish
published: true
title: "#TheDress"
author:
  display_name: ''
  login: ''
  email: ''
  url: ''
wordpress_id: 25922
wordpress_url: http://www.displayblog.com/?p=25922
date: '2015-03-12 19:07:04 -0700'
date_gmt: '2015-03-13 02:07:04 -0700'
categories: []
tags: []
comments: []
---
<p>On February 25, 2015 Tumblr user <a href="http://swiked.tumblr.com/post/112073818575/guys-please-help-me-is-this-dress-white-and">swiked</a> posted a photo of a dress and asked for help to identify its colors. Was it white and gold or black and blue? As of now, 16 days later, there are 3.4 million votes on <a href="http://www.buzzfeed.com/catesish/help-am-i-going-insane-its-definitely-blue">BuzzFeed</a> with a 68/32 <a href="https://twitter.com/search?q=%23whiteandgold">#WhiteandGold</a>/<a href="https://twitter.com/search?q=%23blueandblack">#BlueandBlack</a> split. What happened?</p>
<p>A lot of things happened, I think, but at the core of <a href="https://twitter.com/search?q=%23thedress">#TheDress</a> is color and how we perceive color. I read a lot of different scientific articles about color, light, vision, etc. and here is my summary of what I learned.</p>
<p>COLOR IS NOT A DISCREET THING, and depends on light. Color also depends on how it was captured, and the visual system observing it. Other things color is dependent on are: the lens, the image sensor, the color space used when the image was captured, the compression algorithm, and the display. It doesn't stop there because the display itself has many variables: light source, color space, brightness, contrast ratio, viewing angle, wide viewing angle liquid crystal technology, etc.</p>
<p>LIGHT MAKES COLOR. Let's start with the notion that color is not a discreet thing. Let's also assume we are where we are (but we could theoretically be somewhere else): on earth, with the sun as our natural source of light. Light from the sun passes through the atmosphere of the earth and reaches the surface of the earth. This light from the sun has many wavelengths, from 10<sup>-6</sup> nanometer gamma rays to 100 meter radio waves. The portion of wavelengths that work with our human visual system &mdash; called visible light &mdash; is tiny and from about 400 nm to 700 nm. Here's a short list matching wavelengths to color:</p>
<ul>
<li>~475 nm: blue</li>
<li>~510 nm: green</li>
<li>~570 nm: yellow</li>
<li>~650 nm: red</li><br />
</ul><br />
The mixture of visible light is called white light. We see color when an object absorbs some wavelengths and reflects other wavelengths. For instance, a white car is white because when the sun's light hits the car it absorbs no color and reflects all of them back. Change the light to something else and the white car will no longer be white. Change the human visual system and the white car is no longer white. The white color on the car is not discreet and wholly depends on the light reflecting off of it and the visual system observing it. To get a taste of what I'm talking about hop on over to <a href="http://www.explainxkcd.com/wiki/index.php/1492:_Dress_Color">Explain xkcd</a>, where you can clearly see the color of the dress as dramatically different colors depending on the light that's hitting it.</p>
<p>THE IMPERFECT CAMERA. How was this photo captured? Probably on a smartphone. Let's get into the nitty gritty a bit. The camera hardware subsystem is composed largely of a set of lenses and an image sensor. Anyone who knows anything about photography knows the lens quality makes a significant difference in the quality of the image. I'm sure you've heard of this rule of thumb: "Get a decent camera body, but get the best lens you can afford." That's what I recommend to anyone wanting to get a lens-replaceable camera; lens quality is important. A poor quality lens can make photos blurry, add chromatic aberrations, noise, and vignetting to name some of the more common defects. Unfortunately with rare exceptions most smartphones have lenses that are mediocre at best. Remember light is what makes color; a lot of light makes better color, and vice versa.</p>
<p>Then there's the image sensor. I have to guess smartphone product managers are too swayed by marketing folks who incorrectly believe more pixels on the image sensor will sell more smartphones. How else can I explain why every year the megapixel count on smartphones image sensors grow. I understand we need a certain number of pixels on the sensor, but after a certain number &mdash; I'd say about eight megapixels &mdash; cramming more photosensors will not enhance photo quality; it will actually do the opposite. At about the eight megapixel mark what helps improve photo quality is making each of those pixels or photosensors larger and more sensitive to light (back illuminated sensor). After light goes through the lens, hits the image sensor, photo information is processed by an algorithm. Some smartphones can save this information unprocessed in RAW format, but most photos are the result of this information being compressed; JPEG being the most popular. JPEG is a lossy compression algorithm, which means there is information that is lost due to the compression. </p>
<p>Combine these variables (lens, image sensor, algorithm, compression) and it should be apparent there is ample potential for imperfections to trickle into photos. The iPhone 6 and 6 Plus, the Samsung Galaxy Note 4, and few others have camera subsystems that can capture high quality photos. But even with the best smartphone the same color can be perceived differently.</p>
<p>THE IMPERFECT DISPLAY. Ah, the display. So many companies make so many crappy displays. Even good displays are not calibrated, and the end result is inaccurate colors. There are two main display technologies today: LCD and OLED. A display using LCD technology features an always-on backlight and uses liquid crystals to control how much light goes through each pixel. (There is one exception: the direct-lit RGB LED array backlight.) Unlike LCD, black on an OLED display emits no light, resulting in blacks that are as deep as black holes and whites almost as pure as white light from the sun. Accurate colors are a challenge for both display technologies. Remember the early days of Samsung's Galaxy phones with OLED displays? The blown-out over-saturated colors? Pure yuck; it actually provokes in me a biological reaction similar to the feeling I get when I'm about to throw up. I continue to see these cruddy displays on even the newest Samsung smartphones. Thankfully you can set the display option on a Galaxy Note 4 to Basic, which transforms the display from gut-wrenching to <a href="http://www.displayblog.com/2014/11/18/the-most-color-accurate-mobile-display/">the most accurate mobile display</a> on the planet. The best type of LCD is IPS, but compared to OLED the colors on even the best IPS LCDs are slightly washed out.</p>
<p>You don't even get a choice of OLED when it comes to laptops and monitors; IPS LCD is your only option if you want some semblance of color accuracy, for now. Most laptops and monitors do not come with an easy way to calibrate colors. Thankfully higher-end laptops have slowly shifted away from affordable, but terrible TN-based LCDs to IPS LCDs. Same goes for monitors. When it comes to displays there's a lot to be worked on. I reached out to Raymond Soneira, President of DisplayMate, and asked him what is going on with #TheDress:</p>
<blockquote><p>All of the differences reported are caused by variations in the display calibration and color accuracy of the TV or display it is being viewed on. The ambient lighting for both the display and the photo play a major effect - especially since the photo is strongly backlit. I've analyzed all of these issues with a spectroradiometer in my Display Technology article series. It turns out that the real dress is actually deep blue and black, but any dynamic picture processing or increase in the display's black level setting would produce the light blue and brown/gold image and account for the wide differences reported. The strong backlighting accentuates any display dynamic processing and calibration shifts. The source photo is of poor quality and also to blame.</blockquote></p>
<p>Soneira points out, in addition to non-calibrated displays with poor color accuracy, an important consideration most of us have not considered: ambient lighting. The color of light hitting the dress changes the color, but the light in your room also affects the colors you see on your display. Do you want to experience what-you-see-on-your-display-is-what-you-see-in-real-life or get pretty close to it? I do. Like a good lens for high quality photos, I recommend spending most of your computing budget on a good display, and calibrate it if possible. In my opinion best monitor you can get your hands on today in terms of color accuracy are the HP Dreamcolor professional displays. The smartphone with the best color accuracy is the Samsung Galaxy Note 4 in Basic mode. This is not my opinion, but test proven by Soneira. I also asked Martin Fishman, COO and EVP Worldwide Sales and Marketing at Portrait Displays what he thought was going on. Fishman stressed the importance of display calibration and encouraged everyone to ask this question: "Can you trust what you're looking at on your display?" This is probably the most important question you should ask yourself when buying anything with a display.</p>
<p>The last factor is the bio-psychology of the human visual system, but that topic was way too vast for me, so I will conclude here. There were many factors that influenced our perception of the colors of #TheDress: light, capturing and processing light, and displaying light. All of these factors must have played a role in almost 70%, according to <a href="http://www.buzzfeed.com/catesish/help-am-i-going-insane-its-definitely-blue#.cxpwypy9P">BuzzFeed's survey</a>, getting the colors wrong. The dress is in fact the <a href="http://www.romanoriginals.co.uk/invt/70931">Lace Bodycon Dress</a>, in Royal Blue (<a href="https://twitter.com/search?q=%23blueandblack">#BlueandBlack</a>).</p>
